{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNgJRtLHzUsfNGjIO4vHJkS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")"],"metadata":{"id":"dVH9b4fuZEj9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Training to identify ANSWERS**"],"metadata":{"id":"SR6KWKbjqCq5"}},{"cell_type":"markdown","source":["I tried the following to improve the Question Generator:\n","\n","* Switched from the small T5 to the base\n","* Added the NewsQA dataset\n","* Trained for additional epochs\n","\n","The problem of non-questions and incoherent questions being generated was largely solved. However, the model continued to generate unanswerable questions.\n","\n","A different approach is necessary: *an answer must first be defined*, and based on the chosen answer, a question will be generated."],"metadata":{"id":"4oVhb4QJdecI"}},{"cell_type":"markdown","source":["So, a base T5 was trained, again on the SQuAD dataset, but was this time taught to identify an `answer` based on a `context`."],"metadata":{"id":"ZcGp11BY8Wz3"}},{"cell_type":"code","source":["def tokenize_data(data, tokenizer, source_max_token_len=512, target_max_token_len=32):\n","  tokenized = []\n","  for sample in data:\n","    source = f\"{sample['context']}\".  # source is still context\n","    target = f\"{sample['answer']}\".  # but target is now answer\n","\n","    inputs = tokenizer(source, max_length = source_max_token_len, padding = \"max_length\", truncation = True, return_tensors = \"pt\")\n","\n","    with tokenizer.as_target_tokenizer():\n","      labels = tokenizer(target, max_length=source_max_token_len, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n","\n","    tokenized.append({\n","        \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n","        \"attention_mask\": inputs[\"attention_mask\"].squeeze(0),\n","        \"labels\": labels[\"input_ids\"].squeeze(0)\n","    })\n","  return tokenized"],"metadata":{"id":"qQ7zFuY_87v7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader\n","\n","class T5Dataset(Dataset):\n","    def __init__(self, tokenized_data):\n","        self.tokenized_data = tokenized_data\n","\n","    def __len__(self):\n","        return len(self.tokenized_data)\n","\n","    def __getitem__(self, idx):\n","        return self.tokenized_data[idx]\n","\n","dataset = T5Dataset(tokenized_data=squadt)\n","dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"],"metadata":{"id":"v5dNd6jc88TE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*Training was done on Kaggle, so code is a bit incomplete again*"],"metadata":{"id":"ZFkEi30Y9RYj"}},{"cell_type":"markdown","source":["# **Testing out the Answer Generator**"],"metadata":{"id":"aa-qFT-Mgd8A"}},{"cell_type":"markdown","source":["Input a few longer texts for the model to be tested out on."],"metadata":{"id":"mD8t3XnXgoaT"}},{"cell_type":"markdown","source":["**Humpback Whale Text**"],"metadata":{"id":"7cA96mQF-yar"}},{"cell_type":"code","source":["longcon1 = \"\"\"Humpback whales are one of the most fascinating species in the marine world, known for their impressive size, unique behaviors, and haunting songs. These majestic creatures belong to the family of baleen whales, which includes the largest animals on Earth. Humpback whales can grow up to 60 feet in length and weigh as much as 40 tons, making them one of the larger whale species, though still smaller than the blue whale.\n","\n","One of the most distinctive features of humpback whales is their acrobatic nature. They are known for breaching, a behavior in which the whale propels itself out of the water in a spectacular leap. This behavior, along with their habit of slapping their massive tails and fins on the water's surface, makes humpback whales a favorite among whale watchers. Scientists believe these behaviors could serve multiple purposes, including communication, mating displays, or as a way to dislodge parasites.\n","\n","Humpback whales are also renowned for their complex and melodious songs. Male humpbacks sing intricate songs that can last for up to 20 minutes and be heard miles away under the ocean. These songs are thought to play a role in attracting mates and asserting dominance. Remarkably, all males within a population sing the same song, which evolves gradually over time. The exact meaning and content of these songs remain one of the ocean's great mysteries.\n","\n","Another interesting aspect of humpback whales is their feeding technique known as bubble net feeding. They create a unique \"net\" of bubbles by swimming in a spiral and releasing air from their blowholes. This bubble net traps schools of fish or krill, and the whales then swim upwards with their mouths open to engulf thousands of gallons of water filled with prey. This cooperative hunting strategy showcases the intelligence and social behavior of humpback whales.\n","\n","Humpback whales embark on long migrations, one of the longest of any mammal on Earth. They spend the summer months in colder, polar waters where they feed extensively to build up fat reserves. In the winter, they migrate to warmer, tropical waters to breed and give birth. During the breeding season, humpbacks fast and live off their fat reserves, focusing on mating and nursing their young.\n","\n","Conservation efforts have been critical in protecting humpback whales from the brink of extinction. Once hunted to near extinction, humpback populations have made a significant recovery thanks to international protection and the ban on commercial whaling. However, they still face threats from entanglement in fishing gear, ship strikes, pollution, and climate change which affects their prey availability.\n","\n","The humpback whale continues to capture the human imagination with its beauty, mysterious songs, and awe-inspiring acrobatics. Their presence in the oceans serves as a reminder of the need to preserve and protect the incredible biodiversity of our planet.\"\"\""],"metadata":{"id":"3LmGvpofIhXw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Bioluminescene Text**"],"metadata":{"id":"MNZ62WsF-19N"}},{"cell_type":"code","source":["longcon2 = \"\"\"Let's dive into the fascinating world of bioluminescence, the natural phenomenon where living organisms produce light. Bioluminescence is one of nature's most enchanting spectacles, observed in a variety of organisms, including certain types of fish, insects, fungi, and microorganisms, most notably in the depths of the ocean.\n","\n","The light produced by these organisms is the result of a biochemical reaction in which enzyme luciferase acts on the substrate luciferin, in the presence of oxygen, to produce light. The colors of this light can vary greatly, from the common green or blue to the rare red, depending on the species and the environment in which they live.\n","\n","Bioluminescence serves multiple purposes in nature. For deep-sea creatures, it can be a tool for communication, attracting mates, luring prey, or as a defense mechanism to confuse predators. Fireflies, on the other hand, use bioluminescence to attract mates with their distinctive patterns of flashing lights.\n","\n","One of the most magical occurrences related to bioluminescence is the sea sparkle caused by dinoflagellates, microscopic plankton that illuminate the water along coastlines. When agitated by waves or movement, these organisms emit a stunning, ethereal glow, turning the sea into a canvas of sparkling light.\n","\n","Bioluminescence has not only captivated the imagination of many but has also found practical applications in scientific research. For instance, the gene for luciferase has been inserted into various organisms, from bacteria to plants, making them glow. This technique is used in genetic engineering, bioassays, and medical research to track the expression of genes, monitor the spread of infections, or visualize the location of specific proteins within cells.\n","\n","Despite its widespread occurrence and utility, much about bioluminescence remains a mystery. Deep-sea expeditions continue to discover new species that challenge our understanding of this beautiful biological phenomenon. The study of bioluminescent organisms not only broadens our knowledge of the natural world but also opens up new avenues for biotechnological applications, from eco-friendly lighting solutions to advanced medical diagnostics.\n","\n","As we continue to explore and learn from the natural world, bioluminescence stands as a glowing testament to the wonders of life on Earth, reminding us of the complexity, diversity, and beauty hidden in the depths of the oceans and the nooks of our terrestrial ecosystems.\"\"\""],"metadata":{"id":"7UIlWyQVIhTq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Neuropsychology Text**"],"metadata":{"id":"AkOXx5IG-4Pa"}},{"cell_type":"code","source":["longcon3 = \"\"\"\n","Neuropsychology delves into the intricate relationships between the brain's physical structure and its cognitive functions, exploring how different brain areas and their interconnections underpin specific mental processes and behaviors. A pivotal area within this field is the study of executive functions, which are crucial high-level cognitive processes responsible for organizing, planning, strategizing, paying attention to and remembering details, and managing time and space.\n","\n","Executive functions are primarily mediated by the prefrontal cortex, a part of the brain located at the front of the frontal lobe. This region is involved in the complex processes of decision-making, problem-solving, and behavior modulation. The prefrontal cortex works in tandem with other brain regions to orchestrate a range of activities necessary for goal-directed behavior. For instance, when planning a task, the prefrontal cortex might activate to assess the sequence of actions required, estimate time needed, and predict potential outcomes.\n","\n","Damage or dysfunction in the prefrontal cortex can lead to significant difficulties with executive functions, manifesting in various ways depending on the affected area. For example, damage to the dorsolateral prefrontal cortex can result in problems with working memory and task flexibility, while damage to the orbitofrontal cortex can lead to poor impulse control and decision-making.\n","\n","Executive functions are often assessed through neuropsychological tests designed to probe the complex interplay of cognitive processes involved in goal-directed behavior. These tests might evaluate an individual's ability to form strategies, switch between tasks, apply rules, and inhibit inappropriate responses.\n","\n","Understanding executive functions and their neural underpinnings is not only crucial for basic neuroscience research but also has practical implications in clinical settings. Neuropsychologists apply this knowledge to diagnose and treat conditions characterized by executive dysfunction, such as traumatic brain injury, ADHD, and frontal lobe syndromes. Rehabilitation strategies often include cognitive exercises aimed at improving planning, problem-solving skills, and impulse control, thereby helping individuals regain functionality and improve their quality of life.\n","\n","In sum, the study of executive functions within neuropsychology offers profound insights into how our brains enable us to navigate complex, goal-oriented tasks. It highlights the remarkable capacity of the human brain to adapt and organize behavior in response to ever-changing environmental demands, underscoring the intricate link between brain structure and cognitive function.\"\"\""],"metadata":{"id":"_SJrCKCmI1qW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["I decided to build a \"chunker\" to segment texts in order to:\n","\n","\n","* prevent truncation of an input\n","* allow for more than one question to be generated\n","* logical for longer texts to put out higher amount of questions"],"metadata":{"id":"lWNrKGzE9hZi"}},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n","\n","def chunker(text, tokenizer, min_tokens=140, max_tokens=200):\n","    sentences = nltk.tokenize.sent_tokenize(text)\n","\n","    segments = []\n","    current_segment = []\n","    current_token_count = 0\n","\n","    for sentence in sentences:\n","        sentence_tokens = tokenizer.tokenize(sentence)\n","        sentence_token_count = len(sentence_tokens)\n","\n","        if current_token_count + sentence_token_count > max_tokens:\n","            segments.append(' '.join(current_segment))\n","            current_segment = [sentence]\n","            current_token_count = sentence_token_count\n","        else:\n","            current_segment.append(sentence)\n","            current_token_count += sentence_token_count\n","\n","        if min_tokens <= current_token_count <= max_tokens:\n","            segments.append(' '.join(current_segment))\n","            current_segment = []\n","            current_token_count = 0\n","\n","    if current_segment:\n","        segments.append(' '.join(current_segment))\n","\n","    return segments"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qto9wtYhhYYp","executionInfo":{"status":"ok","timestamp":1710847647804,"user_tz":-60,"elapsed":5257,"user":{"displayName":"Sonia","userId":"08317446953604675933"}},"outputId":"a0f182b5-6555-4d27-9938-695680a03692"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]},{"cell_type":"markdown","source":["# **Comparing Model Performance**"],"metadata":{"id":"_fn-Z1D8-cJ0"}},{"cell_type":"markdown","source":["I had to segment the training data (into 4 parts), because it was too glitchy to fine-tune my model on all of it as once. This means that I ended up with four answer-generating models, trained on 1/4 to 4/4 of the dataset. I thought it would be interesting to compare their performance."],"metadata":{"id":"ByG8s89s98mr"}},{"cell_type":"markdown","source":["* The **baby model** was trained for one epoch on a fourth of the dataset.\n","\n","* The **adult model** was trained for one epoch on all four parts of the dataset."],"metadata":{"id":"tH5AYmo7hywL"}},{"cell_type":"code","source":["babymodel = torch.load(\"/content/drive/My Drive/TeachMy/answermod_d3e1.pth\", map_location = torch.device(\"cpu\"))\n","adultmodel = torch.load(\"/content/drive/My Drive/TeachMy/answermod_d1e1_d2e1_d3e1_d4e1.pth\", map_location = torch.device(\"cpu\"))"],"metadata":{"id":"vbncjJ-OhqhD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Humpback Whales:**"],"metadata":{"id":"0tma7C3h_Ktq"}},{"cell_type":"code","source":["print(\"Baby:\", [gen_baby(segment) for segment in longcon1])\n","print(\"Adult:\", [gen_adult(segment) for segment in longcon1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xpLl7LNmkSwr","executionInfo":{"status":"ok","timestamp":1710799125987,"user_tz":-60,"elapsed":20905,"user":{"displayName":"Sonia","userId":"08317446953604675933"}},"outputId":"fc73455a-3864-47db-9284-7ccce8eee346"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Baby: ['acrobatic', \"slapping their massive tails and fins on the water's surface\", 'bubble net feeding', 'entanglement in fishing gear, ship strikes, pollution, and climate change', 'humpback whale']\n","Adult: ['60 feet', 'humpback whales', 'bubble net feeding', 'entanglement in fishing gear, ship strikes, pollution, and climate change', 'humpback whale']\n"]}]},{"cell_type":"markdown","source":["**Bioluminescence:**"],"metadata":{"id":"sdMAcYXw_Nyj"}},{"cell_type":"code","source":["print(\"Baby:\", [gen_baby(segment) for segment in longcon2])\n","print(\"Adult:\", [gen_adult(segment) for segment in longcon2])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kAgqhxXBkrem","executionInfo":{"status":"ok","timestamp":1710799141031,"user_tz":-60,"elapsed":14041,"user":{"displayName":"Sonia","userId":"08317446953604675933"}},"outputId":"c9e2a0d6-8c77-42f8-871e-387b6688abce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Baby: ['bioluminescence', 'a canvas of sparkling light', 'bioluminescence', 'bioluminescence']\n","Adult: ['bioluminescence', 'Fireflies', 'bioluminescence', 'bioluminescence']\n"]}]},{"cell_type":"markdown","source":["**Neuropsychology:**"],"metadata":{"id":"-R7Py0aE_QuW"}},{"cell_type":"code","source":["print(\"Baby:\", [gen_baby(segment) for segment in longcon3])\n","print(\"Adult:\", [gen_adult(segment) for segment in longcon3])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OGw0nG9vkt7H","executionInfo":{"status":"ok","timestamp":1710799149944,"user_tz":-60,"elapsed":8916,"user":{"displayName":"Sonia","userId":"08317446953604675933"}},"outputId":"510d41d4-8d89-4663-be06-ab379097301c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Baby: ['executive functions', 'prefrontal cortex', 'executive dysfunction', 'brain structure and cognitive function']\n","Adult: ['prefrontal cortex', 'damage to the dorsolateral prefrontal cortex', 'traumatic brain injury, ADHD, and frontal lobe syndromes', 'adapt and organize behavior']\n"]}]},{"cell_type":"markdown","source":["**Conclusions:**"],"metadata":{"id":"BP52Dj9N-kyS"}},{"cell_type":"markdown","source":["* Baby model does surprisingly well, not much difference in answer quality between the two imo.\n","\n","* Both have issues with the bioluminescence text, seems like it has a \"What\" bias.\n","\n","* Based on these 3 examples, especially the adult model seems to show this bias. For the humpback whale text, it defines \"humpback whale/s\" as an answer twice. For the bioluminescence text, it defines \"bioluminescence\" as an answer thrice."],"metadata":{"id":"aI_4hYhDk8Ox"}},{"cell_type":"markdown","source":["This is bad, don't want repetitive/too easy questions and answers."],"metadata":{"id":"_piVLno6_-5S"}},{"cell_type":"markdown","source":["# **Improving the Model**"],"metadata":{"id":"t_3le_ZylZ5F"}},{"cell_type":"markdown","source":["Let's look at what the most common SQuAD questions look like."],"metadata":{"id":"avlUoaJ2leOI"}},{"cell_type":"code","source":["from collections import Counter\n","\n","firstwords = [\" \".join(data[\"question\"].split()[:4]) for data in squadp]\n","firstwordcounts = Counter(firstwords)\n","firstwordcounts.most_common(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4vnj_etPnkm4","executionInfo":{"status":"ok","timestamp":1710846807313,"user_tz":-60,"elapsed":881,"user":{"displayName":"Sonia","userId":"08317446953604675933"}},"outputId":"bf8dcd5b-7433-4eef-889a-837c3668ff51"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('In what year did', 827),\n"," ('What is the name', 776),\n"," ('What was the name', 668),\n"," ('In what year was', 488),\n"," ('What was the first', 178)]"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["The most common questions made by the crowdworkers were pretty lazy ofc, and query very simple things like years and names. That's not good for the model."],"metadata":{"id":"cas4yV0DA84g"}},{"cell_type":"markdown","source":["What about just looking at the first word of each question?"],"metadata":{"id":"vNrJdTJdaRjC"}},{"cell_type":"markdown","source":["*some code is missing, I worked across so many different notebooks ğŸ˜©*"],"metadata":{"id":"P3osVcIaae0g"}},{"cell_type":"code","source":["first_word_percentage = {word: (count / total) * 100 for word, count in first_word_freq}\n","first_word_percentage"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_lqhE8HxObrB","executionInfo":{"status":"ok","timestamp":1710608975633,"user_tz":-60,"elapsed":301,"user":{"displayName":"Sonia","userId":"08317446953604675933"}},"outputId":"6f4c78e8-ebeb-43e9-a06d-6aa3674a078e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'WHAT': 44.882528612611985,\n"," 'WHO': 23.49255122650141,\n"," 'HOW': 8.346424070845346,\n"," 'WHERE': 7.743962436776053,\n"," 'WHEN': 4.258661464896684,\n"," 'WHICH': 2.4909803379999653,\n"," 'THE': 0.7543717309119785,\n"," 'IN': 0.6542491670838441,\n"," 'WHOSE': 0.383227744307687,\n"," 'FOR': 0.2969151892834332}"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","source":["The most common question words are of course \"What\" and \"Who\", as expected. While \"What\" questions can definitely be complex, the above analysis looking at the most common 4-word combinations indicates that most \"What\" questions just referred to the name of something."],"metadata":{"id":"ll86sJysap_e"}},{"cell_type":"markdown","source":["So, I extracted data triplets based on the first word of their respective questions, in order to generate higher quality answers and consequently, questions. I extracted the triplets with the following question words:"],"metadata":{"id":"OMmtJgXnBRzG"}},{"cell_type":"markdown","source":["\n","\n","*   How\n","*   Why\n","* Which\n","\n"],"metadata":{"id":"BwM9MvsyBe-A"}},{"cell_type":"markdown","source":["I then compared the performance between the **old** adult model and the new **\"tuned\"** adult model."],"metadata":{"id":"6hqBjjAJBlOi"}},{"cell_type":"code","source":["adultnew = torch.load(\"/content/drive/My Drive/TeachMy/adult_tuned.pth\", map_location=torch.device(\"cpu\"))"],"metadata":{"id":"rizxXk3W5erN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Humpback Whales:**"],"metadata":{"id":"pq_n8eUXB2AC"}},{"cell_type":"code","source":["print(\"Old:\", [gen_adult(segment) for segment in text1])\n","print(\"New:\", [gen_tuned(segment) for segment in text1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1IUpCl4I7RMp","executionInfo":{"status":"ok","timestamp":1710810334182,"user_tz":-60,"elapsed":14612,"user":{"displayName":"Sonia","userId":"08317446953604675933"}},"outputId":"f19c0736-bf6f-4177-ae7e-af42ac3536b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Old: ['60 feet', 'humpback whales', 'bubble net feeding', 'entanglement in fishing gear, ship strikes, pollution, and climate change', 'humpback whale']\n","New: ['60 feet', '20 minutes', 'by swimming in a spiral and releasing air from their blowholes', 'to build up fat reserves', 'beauty, mysterious songs, and awe-inspiring acrobatics']\n"]}]},{"cell_type":"markdown","source":["* The tuned model does not define \"humpback whales\" as an answer at all, which is great"],"metadata":{"id":"JXwtCxPtCJkZ"}},{"cell_type":"markdown","source":["**Bioluminescence:**"],"metadata":{"id":"A4U9b4NHB4Ez"}},{"cell_type":"code","source":["print(\"Old:\", [gen_adult(segment) for segment in text2])\n","print(\"New:\", [gen_tuned(segment) for segment in text2])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QH6FDzaj7RrV","executionInfo":{"status":"ok","timestamp":1710810341826,"user_tz":-60,"elapsed":7646,"user":{"displayName":"Sonia","userId":"08317446953604675933"}},"outputId":"3868c2bc-09ed-4c2b-c0d3-5ec7e45b3648"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Old: ['bioluminescence', 'Fireflies', 'bioluminescence', 'bioluminescence']\n","New: ['biochemical reaction', 'to confuse predators', 'biotechnological', 'bioluminescence']\n"]}]},{"cell_type":"markdown","source":["* The tuned model puts out 4 unique answers, as opposed to the old one, which has bioluminescence x3"],"metadata":{"id":"Y6GBEVv5CURw"}},{"cell_type":"markdown","source":["**Neuropsychology:**"],"metadata":{"id":"bbeMNtLyB6LR"}},{"cell_type":"code","source":["print(\"Old:\", [gen_adult(segment) for segment in text3])\n","print(\"New:\", [gen_tuned(segment) for segment in text3])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n33eb4un7KRC","executionInfo":{"status":"ok","timestamp":1710810352930,"user_tz":-60,"elapsed":11106,"user":{"displayName":"Sonia","userId":"08317446953604675933"}},"outputId":"859e4f7f-8a13-4e8b-d525-6c9260acf8ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Old: ['prefrontal cortex', 'damage to the dorsolateral prefrontal cortex', 'traumatic brain injury, ADHD, and frontal lobe syndromes', 'adapt and organize behavior']\n","New: ['executive functions', 'through neuropsychological tests', 'traumatic brain injury, ADHD, and frontal lobe syndromes', 'brain structure and cognitive function']\n"]}]},{"cell_type":"markdown","source":["* No problem with the answers from either model"],"metadata":{"id":"NXgUhOOQCd9j"}},{"cell_type":"markdown","source":["Cool! We now have an answer generator. The only step left is to convert the answers into questions. Luckily enough, the question generator made in Part 1 can actually be repurposed for this task and no new model has to be trained."],"metadata":{"id":"5fuPeqSOJ3xj"}}]}