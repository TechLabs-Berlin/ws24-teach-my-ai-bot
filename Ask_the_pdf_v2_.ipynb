{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1eza--iiCs-4kqTnsc8Z98YCstKq9wQyr","timestamp":1709898562093}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T8lSW5ShSywh","outputId":"3b6892a4-febf-4f66-83a7-699965ce2b5a","executionInfo":{"status":"ok","timestamp":1709896079737,"user_tz":-60,"elapsed":12751,"user":{"displayName":"Fernanda Portieri","userId":"02686999081544692809"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.0)\n","Requirement already satisfied: farm-haystack[colab,inference] in /usr/local/lib/python3.10/dist-packages (1.25.0)\n","Requirement already satisfied: boilerpy3 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (1.0.7)\n","Requirement already satisfied: events in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (0.5)\n","Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (0.27.0)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (4.19.2)\n","Requirement already satisfied: lazy-imports==0.3.1 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (0.3.1)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (10.1.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (3.2.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (1.5.3)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (9.0.0)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (4.2.0)\n","Requirement already satisfied: posthog in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (3.5.0)\n","Requirement already satisfied: prompthub-py==4.0.0 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (4.0.0)\n","Requirement already satisfied: pydantic<2 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (1.10.14)\n","Requirement already satisfied: quantulum3 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (0.9.0)\n","Requirement already satisfied: rank-bm25 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (0.2.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (2.31.0)\n","Requirement already satisfied: requests-cache<1.0.0 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (0.9.8)\n","Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (1.4.1.post1)\n","Requirement already satisfied: sseclient-py in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (1.8.0)\n","Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (8.2.3)\n","Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (0.6.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (4.66.2)\n","Requirement already satisfied: transformers==4.37.2 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (4.37.2)\n","Requirement already satisfied: huggingface-hub>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (0.20.3)\n","Requirement already satisfied: sentence-transformers>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (2.5.1)\n","Requirement already satisfied: pyyaml<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from prompthub-py==4.0.0->farm-haystack[colab,inference]) (6.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2->farm-haystack[colab,inference]) (3.13.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2->farm-haystack[colab,inference]) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2->farm-haystack[colab,inference]) (23.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2->farm-haystack[colab,inference]) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2->farm-haystack[colab,inference]) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2->farm-haystack[colab,inference]) (0.4.2)\n","Requirement already satisfied: torch!=1.12.0,>=1.11 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece,torch]==4.37.2; extra == \"inference\"->farm-haystack[colab,inference]) (2.1.0+cu121)\n","Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece,torch]==4.37.2; extra == \"inference\"->farm-haystack[colab,inference]) (0.27.2)\n","Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece,torch]==4.37.2; extra == \"inference\"->farm-haystack[colab,inference]) (0.1.99)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece,torch]==4.37.2; extra == \"inference\"->farm-haystack[colab,inference]) (3.20.3)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.5.0->farm-haystack[colab,inference]) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.5.0->farm-haystack[colab,inference]) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[colab,inference]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[colab,inference]) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[colab,inference]) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[colab,inference]) (2024.2.2)\n","Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack[colab,inference]) (1.4.4)\n","Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack[colab,inference]) (23.2.0)\n","Requirement already satisfied: cattrs>=22.2 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack[colab,inference]) (23.2.3)\n","Requirement already satisfied: url-normalize>=1.4 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack[colab,inference]) (1.4.3)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack[colab,inference]) (1.11.4)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack[colab,inference]) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack[colab,inference]) (3.3.0)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->farm-haystack[colab,inference]) (3.7.1)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->farm-haystack[colab,inference]) (1.0.4)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->farm-haystack[colab,inference]) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->farm-haystack[colab,inference]) (0.14.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack[colab,inference]) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack[colab,inference]) (0.33.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack[colab,inference]) (0.18.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->farm-haystack[colab,inference]) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->farm-haystack[colab,inference]) (2023.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog->farm-haystack[colab,inference]) (1.16.0)\n","Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog->farm-haystack[colab,inference]) (1.6)\n","Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog->farm-haystack[colab,inference]) (2.2.1)\n","Requirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from quantulum3->farm-haystack[colab,inference]) (7.0.0)\n","Requirement already satisfied: num2words in /usr/local/lib/python3.10/dist-packages (from quantulum3->farm-haystack[colab,inference]) (0.5.13)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[sentencepiece,torch]==4.37.2; extra == \"inference\"->farm-haystack[colab,inference]) (5.9.5)\n","Requirement already satisfied: exceptiongroup>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from cattrs>=22.2->requests-cache<1.0.0->farm-haystack[colab,inference]) (1.2.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.11->transformers[sentencepiece,torch]==4.37.2; extra == \"inference\"->farm-haystack[colab,inference]) (1.12)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.11->transformers[sentencepiece,torch]==4.37.2; extra == \"inference\"->farm-haystack[colab,inference]) (3.1.3)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.11->transformers[sentencepiece,torch]==4.37.2; extra == \"inference\"->farm-haystack[colab,inference]) (2.1.0)\n","Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from num2words->quantulum3->farm-haystack[colab,inference]) (0.6.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.11->transformers[sentencepiece,torch]==4.37.2; extra == \"inference\"->farm-haystack[colab,inference]) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.11->transformers[sentencepiece,torch]==4.37.2; extra == \"inference\"->farm-haystack[colab,inference]) (1.3.0)\n"]},{"output_type":"stream","name":"stderr","text":["WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n","WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"]}],"source":["%%bash\n","\n","pip install --upgrade pip\n","pip install farm-haystack[colab,inference]"]},{"cell_type":"code","source":["#for Fernanda's part\n","%%bash\n","\n","pip install PyPDF2\n","pip install nltk\n","pip install PyMuPDF"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KodokvEHGjZ7","outputId":"895a1a6a-1781-4b4b-e027-31ebfa3174d5","executionInfo":{"status":"ok","timestamp":1709896028250,"user_tz":-60,"elapsed":19378,"user":{"displayName":"Fernanda Portieri","userId":"02686999081544692809"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting PyPDF2\n","  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n","Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 232.6/232.6 kB 5.5 MB/s eta 0:00:00\n","Installing collected packages: PyPDF2\n","Successfully installed PyPDF2-3.0.1\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n","Collecting PyMuPDF\n","  Downloading PyMuPDF-1.23.26-cp310-none-manylinux2014_x86_64.whl.metadata (3.4 kB)\n","Collecting PyMuPDFb==1.23.22 (from PyMuPDF)\n","  Downloading PyMuPDFb-1.23.22-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.4 kB)\n","Downloading PyMuPDF-1.23.26-cp310-none-manylinux2014_x86_64.whl (4.4 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.4/4.4 MB 16.7 MB/s eta 0:00:00\n","Downloading PyMuPDFb-1.23.22-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 30.6/30.6 MB 61.1 MB/s eta 0:00:00\n","Installing collected packages: PyMuPDFb, PyMuPDF\n","Successfully installed PyMuPDF-1.23.26 PyMuPDFb-1.23.22\n"]},{"output_type":"stream","name":"stderr","text":["WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n","WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n","WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"]}]},{"cell_type":"code","source":["import logging\n","\n","logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n","logging.getLogger(\"haystack\").setLevel(logging.INFO)"],"metadata":{"id":"yNX8BHRBTDEG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#initializing the document store:\n","from haystack.document_stores import InMemoryDocumentStore\n","\n","document_store = InMemoryDocumentStore(use_bm25=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"octy8VPoTDzg","outputId":"8d820247-f730-4233-dec2-8d05b0da39b8","executionInfo":{"status":"ok","timestamp":1709896110006,"user_tz":-60,"elapsed":11426,"user":{"displayName":"Fernanda Portieri","userId":"02686999081544692809"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:haystack.telemetry:Haystack sends anonymous usage data to understand the actual usage and steer dev efforts towards features that are most meaningful to users. You can opt-out at anytime by manually setting the environment variable HAYSTACK_TELEMETRY_ENABLED as described for different operating systems in the [documentation page](https://docs.haystack.deepset.ai/docs/telemetry#how-can-i-opt-out). More information at [Telemetry](https://docs.haystack.deepset.ai/docs/telemetry).\n","INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n"]}]},{"cell_type":"code","source":["#Fernanda's code for loading the pdf and preprocessing\n","\n","from google.colab import files\n","\n","import PyPDF2\n","import fitz\n","import nltk\n","from collections import Counter\n","from nltk.corpus import stopwords\n","import string\n","\n","nltk.download('stopwords')\n","\n","# Using a technique called n-gram extraction\n","\n","from nltk import bigrams\n","from nltk import FreqDist\n","\n","uploaded = files.upload()\n","\n","def extract_text(file_path):\n","    # Using PyMuPDF to extract text\n","    text = \"\"\n","    with fitz.open(file_path) as pdf_file:\n","        for page_num in range(len(pdf_file)):\n","            page = pdf_file.load_page(page_num)\n","            text += page.get_text()\n","    return text\n","\n","def extract_metadata(file_path):\n","    # Using PyMuPDF for extracting metadata\n","    with fitz.open(file_path) as pdf_file:\n","        metadata = pdf_file.metadata\n","        number_of_pages = len(pdf_file)\n","        return metadata, number_of_pages\n","\n","def preprocess_text(text):\n","    # Lowercase\n","    text = text.lower()\n","    # Punctuation\n","    text = ''.join([char for char in text if char not in string.punctuation])\n","    # Remove common words\n","    stop_words = set(stopwords.words('english'))\n","    text = ' '.join([word for word in text.split() if word not in stop_words])\n","    return text\n","\n","def identify_keywords_and_expressions(text):\n","    words = text.split()\n","    # Identifying frequent words\n","    frequent_words = Counter(words).most_common(50)\n","\n","    excluded_words = {\"was\", \"will\", \"they\", \"are\", \"used\", \"number\", \"many\", \"member\", \"shown\", \"done\", \"blue\", \"eyes\", \"using\", \"use\"}\n","    keywords = [word for word, count in frequent_words if word not in excluded_words and len(word) > 2 and len(word) < 15]\n","\n","    # Extracting bigrams (expressions)\n","    bigram_list = list(bigrams(words))\n","    bigram_freq = FreqDist(bigram_list).most_common(50)\n","    expressions = [' '.join(bigram) for bigram, count in bigram_freq]\n","\n","    # List of the keywords and expressions\n","    print(\"List of keywords:\", keywords)\n","    print(\"List of expressions:\", expressions)\n","    return keywords, expressions\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":107},"id":"RZh9pE5m3ZlO","outputId":"e172db5c-5f12-47af-9d8a-6ee1f2b1fcab","executionInfo":{"status":"ok","timestamp":1709898198905,"user_tz":-60,"elapsed":17817,"user":{"displayName":"Fernanda Portieri","userId":"02686999081544692809"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-c17f4711-1496-4b8d-bc6f-d37a9837016e\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-c17f4711-1496-4b8d-bc6f-d37a9837016e\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving test7.pdf to test7.pdf\n"]}]},{"cell_type":"code","source":["# Arpad, I changed this part as well, see if it makes sense\n","#part to save the the extracted/preprocessed text to an output.txt file which goes to the document store\n","\n","file_path = next(iter(uploaded))\n","\n","text = extract_text(file_path)\n","metadata, number_of_pages = extract_metadata(file_path)\n","\n","text = preprocess_text(text)\n","\n","keywords, expressions = identify_keywords_and_expressions(text)\n","\n","# Checking if metadata function works\n","print(\"Number of Pages:\", number_of_pages)\n","print(\"Length of Text:\", len(text))\n","print(\"Title:\", metadata.get(\"title\", \"Not available\"))\n","print(\"Author:\", metadata.get(\"author\", \"Not available\"))\n","print(\"Summary:\", metadata.get(\"subject\", \"Not available\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dJfM3Yg-3kVM","outputId":"b96771eb-0a66-425b-bda0-6c9dcef2709c","executionInfo":{"status":"ok","timestamp":1709898202302,"user_tz":-60,"elapsed":401,"user":{"displayName":"Fernanda Portieri","userId":"02686999081544692809"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["List of keywords: ['data', 'table', 'graphs', 'charts', 'tables', 'summary', 'audience', 'presentation', 'understand', 'graph', 'chart', 'presenting', 'patterns', 'information', 'statistics', 'objective', 'components', 'types', 'present', 'trends', 'create', 'analysis', 'layout', 'form', 'students', 'categorical', 'grade', 'percentage', 'show', 'interpret', 'clear', 'statistical', 'different', 'step', 'forms', 'dimensions', 'purpose', 'type', 'consider', 'indicators', 'communicate', 'manner', 'easy', 'useful']\n","List of expressions: ['graphs charts', 'charts graphs', 'table •', 'charts •', 'summary table', 'graph chart', 'audience •', 'presenting data', 'data •', 'patterns trends', 'multidimensional tables', 'types graphs', 'objective audience', 'forms presentation', '• tables', '• components', 'components table', 'present data', 'data using', 'form •', '• summary', 'summary tables', 'categorical variable', 'students grade', '– simple', 'multidimensional summary', 'tables •', '• show', 'understand interpret', 'rows columns', 'columns –', 'source data', 'table –', 'numbers –', 'statistical information', 'trends data', 'graphs –', 'different types', 'chart –', 'graph –', 'create graph', '• create', 'percentage table', 'introduction data', 'data analysis', 'analysis greg', 'greg keeble', 'keeble unesco', 'unesco institute', 'institute statistics']\n","Number of Pages: 21\n","Length of Text: 3448\n","Title: PowerPoint Presentation\n","Author: P_Montjourides\n","Summary: \n"]}]},{"cell_type":"code","source":["#write the text to output.txt\n","with open(\"output.txt\", \"w\", encoding='utf-8') as text_file:\n","  text_file.write(text)\n","\n","print(\"Text extracted, preprocessed and saved to output.txt!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kDWZfAZmxP5w","executionInfo":{"status":"ok","timestamp":1709898211139,"user_tz":-60,"elapsed":268,"user":{"displayName":"Fernanda Portieri","userId":"02686999081544692809"}},"outputId":"e0175a77-d346-448c-c226-2e1ebb94529e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Text extracted, preprocessed and saved to output.txt!\n"]}]},{"cell_type":"code","source":["#writing the document(s) to the documentstore\n","import os\n","from haystack.pipelines.standard_pipelines import TextIndexingPipeline\n","\n","# Specify the path to the single text file you want to index\n","path_to_file = \"output.txt\"  # Replace with the actual file path\n","indexing_pipeline = TextIndexingPipeline(document_store)\n","# Directly pass the file path to run_batch, as it accepts both lists and individual paths\n","indexing_pipeline.run_batch(file_paths=[path_to_file])  # Enclose in a list for clarity"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gaDUDE1sTVhW","outputId":"b4e85335-2299-42e3-f5e8-ddb39f1d8472","executionInfo":{"status":"ok","timestamp":1709898214209,"user_tz":-60,"elapsed":277,"user":{"displayName":"Fernanda Portieri","userId":"02686999081544692809"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:haystack.pipelines.base:It seems that an indexing Pipeline is run, so using the nodes' run method instead of run_batch.\n","Converting files: 100%|██████████| 1/1 [00:00<00:00, 315.76it/s]\n","Preprocessing:   0%|          | 0/1 [00:00<?, ?docs/s]WARNING:haystack.nodes.preprocessor.preprocessor:We found one or more sentences whose split count is higher than the split length.\n","Preprocessing: 100%|██████████| 1/1 [00:00<00:00, 267.63docs/s]\n","Updating BM25 representation...: 100%|██████████| 6/6 [00:00<00:00, 1853.56 docs/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["{'documents': [<Document: {'content': 'introduction data analysis greg keeble unesco institute statistics overview • objective audience • forms presentation • tables dimensions • components table • layout table • presenting data • purpose graphs charts • components graphs charts • types graphscharts • data presentation objective audience • type statistics depends main objective presentation target audience • consider best present data indicators – trying communicate – audience – kind presentation effective – help audience better understand data forms presentation communicate audience meaning data using summary statistics informative interesting manner easy understand • tables useful presenting data statistics numeric form • charts graphs may used highlight key patterns trends graphical form • descriptive text describe summarize findings verbal form dimensions summary table • summary tables used present counts students teachers schools categorical variable • eg number teachers qualification number students grade • summary tables – simple onedimensional table one categorical variable – multidimensional table two categorical variables onedimensional summary table table shows number percentage student enrollments grade high school multidimensional summary table multidimensional tables multidimensional tables • show detailed data patterns complex relationships • become complicated many data values presented • need consider ability reader understand interpret multidimensional tables • enable indepth analysis patterns school participation presenting data distribution students grade age gender multidimensional summary table components table properly presented table include – title – headings – rows columns – units measurement – degree accuracy – footnotes – source data layout clear wellstructured layout makes easier reader interpret understand information table – font style – ordering rows columns – numbers – consistent appearance – number table – unnecessary distraction note complex tables logically appear together placed appendices graphs charts • represent summarize statistical information visual manner show patterns trends data • useful highlighting presenting important information • ideal method presenting statistical information nontechnical audiences purpose charts graphs charts graphs used • visually represent information cannot easily read interpreted table • show trends changes statistical data • make comparisons two different set data making make predictions forecasts advantages charts graphs – easier understand table numbers – highlight patterns trends data – makes comparisons analysis easy – representation data using different types graphs charts – allow special designs eg agepyramids thematic maps components charts graphs understand interpret data represented graph chart graphs charts • title • axis labels • labels subgroups • footnotes • references source data characteristics charts graphs – present key message – clear objective – use appropriate type presentation – simple clear design types graphs charts many different types graphs charts including – pie chart – line graph – bar chart – area graph – scatter plot – maps process creating graph chart steps create graph chart 1 organize present data table 2 calculate percentages ratios indicators 3 create graph chart illustrate data step 1 step 2 step 3 practical exercise • create pivot table emis dataset • calculate percentage table • create chartgraph percentage table', 'content_type': 'text', 'score': None, 'meta': {'_split_id': 0}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '56bbd18a8e641d01d7be8be2464e880a'}>],\n"," 'root_node': 'File',\n"," 'params': {},\n"," 'file_paths': ['output.txt'],\n"," 'node_id': 'DocumentStore'}"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["#initializing the retriever\n","from haystack.nodes import BM25Retriever\n","\n","retriever = BM25Retriever(document_store=document_store)"],"metadata":{"id":"e-jl64rZUDAO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from haystack.nodes import FARMReader\n","#if use_gpu=True GPU accerelation (in Edit: Notebook settings) must be enabled\n","reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cZp-r6uEUX14","outputId":"f91727ec-807a-46c4-bc4f-5573cc6e97d8","executionInfo":{"status":"ok","timestamp":1709898224865,"user_tz":-60,"elapsed":1802,"user":{"displayName":"Fernanda Portieri","userId":"02686999081544692809"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n","INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n","INFO:haystack.modeling.model.language_model: * LOADING MODEL: 'deepset/roberta-base-squad2' (Roberta)\n","INFO:haystack.modeling.model.language_model:Auto-detected model language: english\n","INFO:haystack.modeling.model.language_model:Loaded 'deepset/roberta-base-squad2' (Roberta model) from model hub.\n","INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n"]}]},{"cell_type":"code","source":["#creating the retriever-reader pipeline\n","from haystack.pipelines import ExtractiveQAPipeline\n","\n","pipe = ExtractiveQAPipeline(reader, retriever)"],"metadata":{"id":"t5sawA68UcTb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#asking a question:\n","prediction = pipe.run(query=\"What is this report about?\", params={\"Retriever\": {\"top_k\": 10}, \"Reader\": {\"top_k\": 5}})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WZuX5DnlUuq2","outputId":"9da9b21a-ab6a-4602-faef-ae94566f709d","executionInfo":{"status":"ok","timestamp":1709898229287,"user_tz":-60,"elapsed":1256,"user":{"displayName":"Fernanda Portieri","userId":"02686999081544692809"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.34 Batches/s]\n"]}]},{"cell_type":"code","source":["from pprint import pprint\n","\n","pprint(prediction)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AB438m58VBet","outputId":"189e7fc1-07c3-47a6-dcb9-8a866326cb4c","executionInfo":{"status":"ok","timestamp":1709898238051,"user_tz":-60,"elapsed":365,"user":{"displayName":"Fernanda Portieri","userId":"02686999081544692809"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'answers': [<Answer {'answer': 'international journal innovative technology', 'type': 'extractive', 'score': 0.33749920129776, 'context': 'howing box plot manufacturer reviewsrating data frame international journal innovative technology exploring engineering ijitee issn 22783075 volume8 i', 'offsets_in_document': [{'start': 3886, 'end': 3929}], 'offsets_in_context': [{'start': 54, 'end': 97}], 'document_ids': ['e7ccf0338259516ca95d3b8db3be9f05'], 'meta': {'_split_id': 0}}>,\n","             <Answer {'answer': 'innovative technology exploring engineering ijitee issn 22783075 volume8 issue12 october 2019 4727 published blue eyes intelligence engineering sciences', 'type': 'extractive', 'score': 0.2875562310218811, 'context': 'innovative technology exploring engineering ijitee issn 22783075 volume8 issue12 october 2019 4727 published blue eyes intelligence engineering sciences', 'offsets_in_document': [{'start': 22, 'end': 174}], 'offsets_in_context': [{'start': 0, 'end': 152}], 'document_ids': ['2448d9e2251738fcb7f920426d0cdf72'], 'meta': {'_split_id': 0}}>,\n","             <Answer {'answer': 'sales would increase temperature rose', 'type': 'extractive', 'score': 0.1691364049911499, 'context': ' study parameters mean parameter slope indicating amount sales would increase temperature rose degree number seems 1674 units usddegree already seems ', 'offsets_in_document': [{'start': 2315, 'end': 2352}], 'offsets_in_context': [{'start': 57, 'end': 94}], 'document_ids': ['3cdb3d6efef9dc80cca237d71b824dad'], 'meta': {'_split_id': 0}}>,\n","             <Answer {'answer': 'innovative technology exploring engineering', 'type': 'extractive', 'score': 0.1561587154865265, 'context': ' taking entire feature variable international journal innovative technology exploring engineering ijitee issn 22783075 volume8 issue12 october 2019 47', 'offsets_in_document': [{'start': 8465, 'end': 8508}], 'offsets_in_context': [{'start': 54, 'end': 97}], 'document_ids': ['2448d9e2251738fcb7f920426d0cdf72'], 'meta': {'_split_id': 0}}>,\n","             <Answer {'answer': 'data analysis', 'type': 'extractive', 'score': 0.14684368669986725, 'context': 'life informing boss supervisor you’ve 2 let’s consider basic outline data analysis report detail 1 introduction good features introduction include • s', 'offsets_in_document': [{'start': 2769, 'end': 2782}], 'offsets_in_context': [{'start': 69, 'end': 82}], 'document_ids': ['cd1ebf199eeab768117d9f0dbf19bc6e'], 'meta': {'_split_id': 0}}>],\n"," 'documents': [<Document: {'content': 'introduction data analysis greg keeble unesco institute statistics overview • objective audience • forms presentation • tables dimensions • components table • layout table • presenting data • purpose graphs charts • components graphs charts • types graphscharts • data presentation objective audience • type statistics depends main objective presentation target audience • consider best present data indicators – trying communicate – audience – kind presentation effective – help audience better understand data forms presentation communicate audience meaning data using summary statistics informative interesting manner easy understand • tables useful presenting data statistics numeric form • charts graphs may used highlight key patterns trends graphical form • descriptive text describe summarize findings verbal form dimensions summary table • summary tables used present counts students teachers schools categorical variable • eg number teachers qualification number students grade • summary tables – simple onedimensional table one categorical variable – multidimensional table two categorical variables onedimensional summary table table shows number percentage student enrollments grade high school multidimensional summary table multidimensional tables multidimensional tables • show detailed data patterns complex relationships • become complicated many data values presented • need consider ability reader understand interpret multidimensional tables • enable indepth analysis patterns school participation presenting data distribution students grade age gender multidimensional summary table components table properly presented table include – title – headings – rows columns – units measurement – degree accuracy – footnotes – source data layout clear wellstructured layout makes easier reader interpret understand information table – font style – ordering rows columns – numbers – consistent appearance – number table – unnecessary distraction note complex tables logically appear together placed appendices graphs charts • represent summarize statistical information visual manner show patterns trends data • useful highlighting presenting important information • ideal method presenting statistical information nontechnical audiences purpose charts graphs charts graphs used • visually represent information cannot easily read interpreted table • show trends changes statistical data • make comparisons two different set data making make predictions forecasts advantages charts graphs – easier understand table numbers – highlight patterns trends data – makes comparisons analysis easy – representation data using different types graphs charts – allow special designs eg agepyramids thematic maps components charts graphs understand interpret data represented graph chart graphs charts • title • axis labels • labels subgroups • footnotes • references source data characteristics charts graphs – present key message – clear objective – use appropriate type presentation – simple clear design types graphs charts many different types graphs charts including – pie chart – line graph – bar chart – area graph – scatter plot – maps process creating graph chart steps create graph chart 1 organize present data table 2 calculate percentages ratios indicators 3 create graph chart illustrate data step 1 step 2 step 3 practical exercise • create pivot table emis dataset • calculate percentage table • create chartgraph percentage table', 'content_type': 'text', 'score': 0.5, 'meta': {'_split_id': 0}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '56bbd18a8e641d01d7be8be2464e880a'}>,\n","               <Document: {'content': 'introduction data analysis learning goals • understand display data lab report • study analyze fits parameters • understand arrive conclusions data introduction lab spend abundance time collecting data take time come good way displaying data whether table graph however alone enough arrive physical conclusions know interpret data convey ideas reader process known data analysis document discuss analyze data provide working example walk thoughtprocess analyzing data committing findings paper setting scene guiding example document let’s consider following scenario i’ve gathered data number ice cream sales versus daily high temperature wanted find relationship two variables stands reason would expect variables share linear relationship refer amount sales usd temperature fahrenheit would make sense obey linear relationship ∗ b 1 1 introduction data analysis setting scene figure 1 ice cream sales versus daily high temperature graphs total number sales span week average daily high temperature week data error shown blue points figure best fit line shown red fit demonstrates almost linear relationship temperature regime slope b yintercept need understand correspond real world let’s leave mathematical variables table data appendix plot generated using techniques learned excel shown figure 1 note whenever put figure report need title properly labeled aces caption fully details shown rule thumb someone get gist you’re trying say reading captions coming graph want use linest function discussed previous document uncertainty error obtain fit parameters goodness fit particular fit linest function tells 1674 ± 158 b −69607 ± 10433 r2 091 2 always good check see things ok error substantially smaller actual value b derived arrive equation describing fit well r2 value characterizes goodness fit want conduct following steps 2 introduction data analysis putting pen paper 1 understand parameters relate variables physical interest 2 propagate error fit variables variables physical interest 3 determine whether errors parameters small enough values reliable match known results 4 determine whether parameter values reliable based goodness fit 5 display results table 6 state findings writing let’s walk steps example figure put lab report first want study parameters mean parameter slope indicating amount sales would increase temperature rose degree number seems 1674 units usddegree already seems like useful quantity lab report may write report amount money you’d earn sales per degree fahrenheit 1674 ± 158 usd◦f 3 next parameter b yintercept tells i’d make negative 700 dollars 0 degrees fahrenheit clearly something wrong since won’t sudden owe people money doesn’t mean model wrong means become bad model certain temperature report would report statistic indicating temperature temperatures studied well 0 model longer reliable explain saying point get certain temperature one buying ice cream anymore also add certain point one buy ice cream temperature hot ie heat wave therefore way understand model one accurate temperature regime went far far would longer good model lastly want look goodness fit rule thumb r2 value greater 09 fit matches data well since r2 value 091 fit matches data well important note point we’ve gathered enough analysis put writing putting pen paper gathered analysis time present argument paper job 3 introduction data analysis putting pen paper 1 present data reader legible fashion 2 justify results data reliable 3 draw connections physical results conclusions data 4 justify reader physical results trusted end example data analysis section data analysis measured total sales ice cream week long span recorded average versus average daily high temperature week error based standard deviation measurements took throughout week data figure 2 data shown blue bestfit line shown red best fit line linear fit matches data well verified r2 − 096 figure 2 passing yards touchdowns graphs yardage gained quarterbacks yaxis number passing touchdowns achieved quarterbacks xaxis data points blue error bars yardage shown black red line demonstrate decent linear relationship fit parameters slope yintercept b slope related amount sales per unit change temperature value 1674 ± 158 usd◦f 4 4 introduction data analysis conclusion useful predicting profit margins local ice cream business store fit parameter b immediate realworld significance hand implies constraint reliability model fit parameters demonstrates extrapolate linear fit temperatures ice cream business would paying money people buying ice cream situation would happen realworld therefore lower temperatures expect linear fit longer work taper off towards 0 earned without going negative also true high temperature regime certain point would difficult people go outside get ice cream must decrease temperatures get exceedingly high therefore relevance fit parameter tells us linear fit model relevant regime temperatures interest fit parameters fit statistic r2 contained table 1 table 1 fit parameters parameter value error 8896 yardstouchdown 347 yardstouchdown g 8712 yards 606 yards z 22946 yards 1161 yards r2 096 since errors sufficiently small compared values results indeed good estimates experimentally measured values addition matches literature value 17 usd per unit temperature indicating results consistent previous expectations dodd 2022 see able present data graph fit parameters table justify results reliable draw conclusions physically relevant variables less expect see lab reports conclusion applying lab reports remember need understand important equations applying data collect data figure best display data match equations previously derived moreover need justify trust data done error analysis good luck future lab reports 5 introduction data analysis appendix appendix table 2 passing yards touchdowns raw data temperature ◦f sales usd error sales usd 576 215 15 615 325 14 534 185 15 594 332 12 653 406 5 718 522 19 669 412 18 772 614 10 741 544 17 646 421 15 727 445 22 631 408 8 6', 'content_type': 'text', 'score': 0.5, 'meta': {'_split_id': 0}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3cdb3d6efef9dc80cca237d71b824dad'}>,\n","               <Document: {'content': 'structure data analysis report data analysis report somewhat different types professional writing may done seen learn future related • typical psychsocial science paper orgainzed around “intromethodsanalysisresultsdiscussion” sections • research article academic journal • essay • lab report science class overall structure data analysis report simple 1 introduction 2 body 3 conclusionsdiscussion 4 appendixappendices data analysis report written several different audiences time • primary audience primary collaborator client reads introduction perhaps conclusion find conclusions perhaps fishesskims body stopping additional details parts heshe thought interesting eyecatching organize paper around agenda conversation want person you’ve learned data eg general specific important least important etc provide main evidence analysis tabular graphical otherwise body support point conclusion reach save detailed evidence ancillary material appendix • secondary audience executive person probably skims introduction perhaps ulconclusion find conclusions leave signposts introduction body conclusion make easy person swoop find “headlines” work conclusions swoop back • secondary audience technical supervisor reads body examines appendix quality control good job raising answering interesting questions efficient reach reasonable conclusions defensible statistical methods etc make specific crossreferences body specific parts appendix person easily find supporting ancillary material related main analysis report ˘body add text technical material appendix person sees carried detailed work shown appendix 1 data analysis report two important features • organized way makes easy different audiences skimfish find topics level detail interest • writing invisibleunremarkable possible content analysis reader remembers distracting quirks tics writing examples distractions include – extra sentences overly formal flowery prose extreme overly casual overly brief prose – grammatical spelling errors – placing data analysis broad narrow context questions interest primary audience – focusing process rather reporting procedures outcomes – getting bogged technical details rather presenting necessary properly understand conclusions substantive questions interest primary audience less important worry latter two items appendix expected detailed processoriented however enough text annotating technical material appendix reader see carried detailed work shown data analysis report isn’t quite like research paper term paper class like research article journal meant primarily start organized conversation clientcollaborator sense kind “internal” communication sort like extended memo hand also “external” life informing boss supervisor you’ve 2 let’s consider basic outline data analysis report detail 1 introduction good features introduction include • summary study data well relevant substantive context background framing issues • “big questions” answered data analyses summaries conclusions questions • brief outline remainder paper pretty good order present material well 2 body body organized several ways two often work well • traditional divide body several sections level introduction names like – data – methods – analysis – results format familiar written psych research papers often works well data analysis paper well though one problem methods section often sounds like bit stretch psych research paper methods section describes get data data analysis paper describe analyses performed without results well pretty sterile sounding often merge “methods” pieces “analysis” section write • questionoriented format single body section usually called “analysis” subsection question raised introduction usually taken order introduction general specific decreasing order importance etc within subsection statistical method analyses conclusion would described question example 2 analysis 21 success rate methods analysis conclusions 22 time relapse methods analysis conclusions 3 23 effect gender methods analysis conclusions 24 hospital effects methods analysis conclusions etc organizational formats possible whatever format useful provide one two wellchosen tables graphs per question body report two reasons first graphical tabular displays convey points efficiently words second “skimming” audiences likely eye caught interesting graph table running text however much graphicaltabular material break flow text become distracting extras moved appendix 3 conclusionsdiscussion conclusion reprise questions conclusions troduction perhaps augmented additional observations details gleaned analysis section new questions future work etc also raised 4 appendixappendices one appendices place details ancillary materials might include items • technical descriptions unusual statistical procedures • detailed tables computer output • figures central arguments presented body report • computer code used obtain results cases especially case computer code good idea add text sentences comments annotations make easier uninitiated reader follow often difficult find right balance put appendix put body paper generally put enough body make point refer reader specific sections page numbers appendix additional graphs tables details 4', 'content_type': 'text', 'score': 0.5, 'meta': {'_split_id': 0}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'cd1ebf199eeab768117d9f0dbf19bc6e'}>,\n","               <Document: {'content': 'ne learning deep learning interest transdisciplinary areas research covering design iot based solutions safety ambient monitoring underground opencast mines areas mining environment safety dr subhendu kumar pani mtech computer science engineering kiit university odisha 2007 phd computer science utkal university 2013 dr pani worked lecturer august 2003 january2005 assistant professor february 2005 – september 2012 pg department computer application regional college management bhubaneswar present dr pani working associate professor dept comp sc engg research coordinator orissa engineering college bhubaneswar since september 2012 dr pani’s primary interest teaching pg ug level includes programming c dstc using c oops using c java programming j2ee iwt dbms data mining data warehousing ooad dccn parallel computing real time systems rts dr pani’s fellow member ssarsc india life member institute engineers india life member iste india life member indian science congressisc india life member orissa bigyan academy oba bhubaneswar life member odisha mathematical society oms senior member iacsit senior member uacee member board studies pn auto college utkal university dr pani published 50 papers reputed national international journals 33 papers conferences proceedings published four articles book chapters edited two books authored five books supervising seven phd scholars reputed universities supervised 19 mtech dissertations examined three phd theses delivered many invited talks associated 25 international conferences workshops seminars symposiums etc member program committee advisory committee editorial committee organizing committee technical committee advisory committee etc dr pani reviewers many international journals attended many shortterm professional courses reputed institutions chaired many sessions international conference', 'content_type': 'text', 'score': 0.5, 'meta': {'_split_id': 0}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f05eb6ac30fdada6bf2d4d96211ec607'}>,\n","               <Document: {'content': 'a set going analyse data possible set options 1 first step imported pandas libraries numpy packages 2 imported fairly large amazon csv file data frame df gives data sets form rows column csv file 5 rows 20 columns used head method return top 5 rows data frame series shown figure 2 3 choose right visualization method visualizing individual variables important first understand type variable dealing help us find right visualization method variable imported matplot lib seaborn library packages used dfdtypes list data column shown figure 3 shown figure reviewsdorecommend boolean data type reviewsid float64 data type reviewsnumhelpful reviewsrating int64 data type object data types 4 used dfcorr find pair wise correlations column data frame gives following correlations reviewsid reviewsdorecommened reviewsnumhelpful reviewsrating pair wise correlations shown figure 4 figure 2 importing pandas library head functions showing top 5 rows data frame 5 done scatter plot reviewsid reviewsrating get following output scatter plot reviewsid reviewsrating shown figure 5 6 find correlation reviewsid exploratory data analysis using python 4730 published blue eyes intelligence engineering sciences publication retrieval number l35910812192019©beiesp doi 1035940ijiteel35911081219 reviewsrating form scatter plot correlation reviewsid reviewsrating shown scatter plot presented figure 6 7 box plot used categorical variable takes fixed number possible values describes characteristics data unit represented box plot done box plot 1 manufacturers reviews ratings 2 manufacturer reviews ratings shown box plot manufacturer number reviewsrating presented figure7 8 count plot used count plot count observations taught histogram across categorical variable identical bar plot made count plot manufacturer reviewsid got following output shown box plot manufacturer number reviewsrating data frame presented figure8 figure3 showing data types column data frame figure4 showing pair wise correlations data frame 9 descriptive statistical analysis used descriptive statistical analysis used describe entire data sets single value metric describe function automatically computes basic statistics continuous variables nan values automatically skipped statistics mean value calculated taking sum values data set divided total number data sets found count variable mean standard deviation std minimum value iqr interquartile range 25 50 75 maximum value found factor reviewsid reviews numhelpful reviews rating used describe function got following output shown count plot amazon manufacturer reviewsid presented figure9 10 counts used count function returns number occurrences tells many units characteristic variable got number brand value different categories electronic products shown output describe function presented figure10 applied method describe variables type object got result 11 basic grouping used group method groups data different categories data grouped based one several variables analysis performed individual groups shown describe method variable type object presented figure11 12 used unique international journal innovative technology exploring engineering ijitee issn 22783075 volume8 issue12 october 2019 4731 published blue eyes intelligence engineering sciences publication retrieval number l35910812192019©beiesp doi 1035940ijiteel35911081219 method know types unique values column returned presented figure12 showing implementation value count function figure5 shows reg plot scatter plot reviewsid reviewsrating figure6 correlation reviewsid reviewsrating scatter plot exploratory data analysis using python 4732 published blue eyes intelligence engineering sciences publication retrieval number l35910812192019©beiesp doi 1035940ijiteel35911081219 figure7 showing box plot manufacturer number reviewsrating figure8 showing box plot manufacturer reviewsrating data frame international journal innovative technology exploring engineering ijitee issn 22783075 volume8 issue12 october 2019 4733 published blue eyes intelligence engineering sciences publication retrieval number l35910812192019©beiesp doi 1035940ijiteel35911081219 figure9 showing count plot amazon manufacturer reviewsid figure10 showing output describe function figure11 shows describe method variable type object figure12 showing implementation value count function exploratory data analysis using python 4734 published blue eyes intelligence engineering sciences publication retrieval number l35910812192019©beiesp doi 1035940ijiteel35911081219 figure 13 shows implementations unique function vi conclusion article explained detail explorative data analysis used language python programming language implementation used jupyter note book detail analysis implemented different library packages python got required result taking different parameter future use data sets functions get clear idea related exploratory dat analysis references 1 aindrila ghosh mona nashaat james miller shaikh quader chad marston “a comprehensive review tools exploratory analysis tabular industrial datasets” visual informatics volume 2 issue 4 december 2018 pp 235253 2 john behrens “principles procedures exploratory data analysis” psychological methods 1997 vol 2 2 pp131160 3 chokey wangmo “an exploratory study bank lending sme sector bhutan” international journal scientific technology research volume 6 issue 11 november 2017 pp 4751 4 matthew ntowgyamfi sarah serwaa boateng “credit risk loan default among ghanaian banks exploratory study” management science letters vol 3 2013 pp753–762 5 x francis jency v p sumathi janani shiva sri “an exploratory data analysis loan prediction based nature clients” international journal recent technology engineering ijrte volume7 issue4s november 2018 pp176179 6 k ulaga priya pushp k kalaivani sartiha “exploratory analysis prediction loan privilege customers using random forest” international journal engineering technology vol 7 issue 221 2018 pp 339341 7 bogumil konopka felicja lwow magdalena owczarz łukasz łaczmański “exploratory data analysis clinical study group development procedure exploring multidimensional data” plos one online httpswwwncbinlmnihgovpmcarticles pmc6107146pdfpone0201950pdf august23 2018 pp 121 8 introduction machine learning using python online available httpswwwgeeksforgeeksorgintroductionmachinelearningusingp ython 9 exploratory data analysis – wikipedia free encyclopedia online available httpsenwikipediaorgwikiexploratorydata analysis authors profile ms kabita sahoo completed btech degree information technology jagannath institute technology management jitm paralakhemundi year 2005 mtech degree computer science engineering cse bput odisha year 2010 qualified ugc net exam november 2017 present pursuing phd degree bput odisha worked asst prof cse driems sep 2006 june 2012 asst prof cse centurion university technology management cutm bhubaneswar june 2012 august 2017 august 16 2016 working asst professor computer science mits school biotechnology bhubaneswar teaching advanced computer architecture computer organization microprocessor operating systems computer graphics unified modeling language vb php mis undergraduate classes guided many academic projects b tech tech level published many research articles articles national international journals conference proceedings participated many skill technical workshops presented papers national level seminar dr abhaya kumar samal msc electronics sambalpur university mca mecse nit rourkela mba specialization marketing systems utkal university phd computer science engineering sambalpur university service experience includes around 17 years working industry sail rsp osedc govt odisha around 18 years experience field academics research working many technical institutions currently dr samal working trident academy technology bhubaneswar deanproject consultancy professor computer science engineering dr samal’s primary domains research academic interest includes rt systems faulttolerant computing embedded systems soft computing ai ml dl iot wsn computer networking software engineering system software interest transdisciplinary research includes design iot based solutions safety ambient monitoring underground opencast mines dr samal published 25 papers reputed national international journals conferences proceedings published three book chapters one book engineering domain supervising six phd scholars bput registered four patents attended many shortterm professional courses reputed institutions chaired many sessions international conference delivered many invited talks upcoming key areas technology delivered keynote addresses national international conferences iot guided many mtech dissertations dr samal fellow institute engineers india – iei fellow institution electronics telecommunication engineers iets life member indian society technical education iste life member computer society india csi life member odisha society oits member ieee mr jitendra pramanik completed btech degree electronics communication engineering bput odisha year 2012 mtech degree communication systems ece centurion university international journal innovative technology exploring engineering ijitee issn 22783075 volume8 issue12 october 2019 4735 published blue eyes intelligence engineering sciences publication retrieval number l35910812192019©beiesp doi 1035940ijiteel35911081219 technology management cutm odisha india year 2015 mr pramanik worked lecturer department ece ocem bhubaneswar aug 2013 may 2014 continuing asst professor cutm since 2017 published many papers reputed national international journals conference proceedings published one book engineering domain credit area teaching interest includes microprocessor microcontroller digital electronics programming c c java python programming matlab system programming wsn iot mr pramanik’s area research academic interest includes embedded systems soft computing artificial intelligence internet things wireless sensor network machi', 'content_type': 'text', 'score': 0.5, 'meta': {'_split_id': 0}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e7ccf0338259516ca95d3b8db3be9f05'}>,\n","               <Document: {'content': 'international journal innovative technology exploring engineering ijitee issn 22783075 volume8 issue12 october 2019 4727 published blue eyes intelligence engineering sciences publication retrieval number l35910812192019©beiesp doi 1035940ijiteel35911081219 \\uf020 abstract data need analyzed produce good result using result decision taken example recommendation system ranking page demand fore casting prediction purchase product leading companies review customer plays great role analyze factor influences review rating used exploratory data analysis eda data interpretations done row column format used python data analysis object oriented interpreted interactive programming language open source rich sets libraries like pandas matplotlib seaborn etc used different types charts various types parameter analyze amazon review data sets contains reviews electronic data items used python programming data analysis keywords exploratory data analysis eda matpplotlib seaborn visualization pandas jupyter notebook introduction data growing faster today’s world easy process data manually data analysis visualization programs allow reaching even deeper understanding programming language python english commands easytofollow syntax offers amazingly powerful free opensource alternative traditional techniques applications data analytics allow businesses understand efficiency performance ultimately helps business make informed decisions example ecommerce company might interested analyzing customer attributes order display targeted ads improving sales data analysis applied almost aspect business one understands tools available process information ecommerce companies analyzing reviews customer using proper visualization method exploratory data analysis eda approach summarize data taking main characteristics visualize proper representations eda focuses narrowly checking assumptions required model fitting hypothesis testing handling missing values making transformations variables needed eda encompasses ida eda quickly describes data sets number rowscolumns missing data data types preview clean corrupted data handle missing data invalid data types revised manuscript received october 05 2019 corresponding author kabita sahoo asst professor dept computer science mits school biotechnology utkal university bhubaneswar india abhaya kumar samal professor dept comp sc engg trident academy technology bhubaneswar india jitendra pramanik asst professor centurion university technology management odisha india subhendu kumar pani associate professor orissa engineering college bhubaneswar india incorrect values eda visualize data distributions bar charts histograms box plots calculate visualize correlations relationships variables heat map rest paper organized follows section ii presents brief review literature section iii presents discussion various techniques exploratory data analysis section iv discusses conduct exploratory data analysis using python section v presents work data sets conduct exploratory data analysis finally section vi presents concluding remarks ii literature survey aindrila ghosha et al 1 examined different data exploration tool exploratory analysis described data exploration tool author john behrens 2 described difference classical data analysis exploratory data analysis using different visualization method chokey wangmo 3 done exploratory study bank lending sme sector bhutan matthew ntowgyamfi et al 4 done exploratory study credit risk loan default among ghanaian banks xfrancis jency et al 5 done exploratory data analysis loan prediction depending upon nature client used machine learning techniques predictive data analysis k ulaga priya1 et al 6 done exploratory analysis prediction loan privilege customers using random forest used r programming exploratory data analysis bogumil konopka et al 7 done exploratory data analysis clinical study group development procedure exploring multidimensional data iii techniques eda exploratory data analysis eda primarily exploratory data analysis approach see data communicate us away formal modeling hypothesis testing task eda helps analyze data sets summarize statistical characteristics focusing four key aspects like measures central tendency comprising mean mode median measures spread comprising standard deviation variance shape distribution existence outliers following paragraphs presented description key aspects eda shown figure 1 every step machine learning process data analysis visualization techniques extensively used techniques discussed data exploration exploratory data analysis using python kabita sahoo abhaya kumar samal jitendra pramanik subhendu kumar pani exploratory data analysis using python 4728 published blue eyes intelligence engineering sciences publication retrieval number l35910812192019©beiesp doi 1035940ijiteel35911081219 first stage data analysis know content data set characteristic data set tells size data find missing value data find possible relationship among data data visualization done use tabular data understanding characteristics figure1 steps machine learning process ii data cleaning process detecting corrupt data removing irrelevant parts data replacing correct data actual process data cleaning remove error validating data data cross checked remove error issue resolved validating data iii model building use statistical model machine learning model describe variable working variable model supervised unsupervised model use classification regression model get output visualize result use model evaluate model iv present result visualize large amount complex data use chart graph tables human brain process information using chart graphs easy way convey concept identify area needs improvement clarify factor well b graphical eda fundamentally graphical exploratory data analysis nothing graphical counterpart traditional nongraphical eda analyzes data sets help summarize statistical characteristics focusing four key aspects like measures central tendency measures spread shape distribution existence outliers categorized geda univariate geda bivariate geda multivariate geda following paragraphs discussed key varieties aspects geda univariate graphical eda univariate geda provides statistical summary field raw data set summary one variable example types geda includes cumulative distribution function cdf probability density function pdf box plot violin plot discussed histograms represent distribution numerical data use histogram histogram relate one variable rather two variables entire range value divided series interval histograms mainly used continuous data histogram represented frequency distribution means rectangle width represents class interval area proportional corresponding frequencies height represents average frequency density tonal distribution digital image graphical representation called image histogram ii stem plots otherwise called leaf plot data spitted two parts largest digit represents stems smallest digit represents leaves little information represented stem plot histogram also used visualization purpose comparing data much easier numbers arranged place value basically used highlighting mode used small data sets iii box plots good graphical image concentration data represented use box plot shows central tendency symmetry skew outlier constructed five values minimum first quartile median third quartile maximum value values compared show close data values bivariate graphical eda bivariate geda accomplished understand connections variable dataset target variable interest using two variables finding connection among example types geda includes box plot violin plot multivariate graphical eda multivariate geda accomplished understand connections different fields dataset finding connections two variables example types geda includes pair plot 3d scatter plot bargraph plot commonly used graphical technique nowadays box plot used show relationship two values cases pair plot used show view variable relationship sidebyside box plots comparing levels possible values use side side box plotit used compare two data sets basically summarize data instant categorical variable ii scatter plots type plot cartesian coordinate used display values two variables set data draw taking variable value x axis axis data displayed collection points value x axis axis gives value variable iii heat maps 3d surface plots generate heat map taking entire feature variable international journal innovative technology exploring engineering ijitee issn 22783075 volume8 issue12 october 2019 4729 published blue eyes intelligence engineering sciences publication retrieval number l35910812192019©beiesp doi 1035940ijiteel35911081219 feature variables taken row column header variable versus diagonal useful visualize relationship variables high dimensional space iv eda python using python exploratory data analysis simple learn rich sets libraries data handling capacity much higher used open source language capacity third party language run platform transfer process one platform another easy read developer understand code offers variety libraries uses great visualization tool visualization process make easier create clear report pandas powerful package data analysis clean transform analyze data data stored csv format computer cleaning visualizing storing data done built top numpy package plotting functions matplotlib machine learning algorithm scikitlearn jupiter notebook gives ability execute code particular cell gives console based approach computing provides web based application process includes input output computation gives rich media representation object applications eda 1 mistakes anomalies detected using eda 2 gain new insight various types data 3 outliers data detected 4 test assumption using eda 5 important factors identified using 6 understand relationship among various data 7 data speak using visualization process v working data sets it’s time explore data find data using belongs amazon review dat', 'content_type': 'text', 'score': 0.5, 'meta': {'_split_id': 0}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '2448d9e2251738fcb7f920426d0cdf72'}>],\n"," 'no_ans_gap': -0.27302098274230957,\n"," 'node_id': 'Reader',\n"," 'params': {'Reader': {'top_k': 5}, 'Retriever': {'top_k': 10}},\n"," 'query': 'What is this report about?',\n"," 'root_node': 'Query'}\n"]}]},{"cell_type":"code","source":["from haystack.utils import print_answers\n","\n","print_answers(prediction, details=\"minimum\")  ## Choose from `minimum`, `medium`, and `all`"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UXNyk1ovVCFV","outputId":"4e04b7ff-a19c-456f-e338-ee3d2a9d0bbb","executionInfo":{"status":"ok","timestamp":1709898244165,"user_tz":-60,"elapsed":267,"user":{"displayName":"Fernanda Portieri","userId":"02686999081544692809"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["'Query: What is this report about?'\n","'Answers:'\n","[   {   'answer': 'international journal innovative technology',\n","        'context': 'howing box plot manufacturer reviewsrating data frame '\n","                   'international journal innovative technology exploring '\n","                   'engineering ijitee issn 22783075 volume8 i'},\n","    {   'answer': 'innovative technology exploring engineering ijitee issn '\n","                  '22783075 volume8 issue12 october 2019 4727 published blue '\n","                  'eyes intelligence engineering sciences',\n","        'context': 'innovative technology exploring engineering ijitee issn '\n","                   '22783075 volume8 issue12 october 2019 4727 published blue '\n","                   'eyes intelligence engineering sciences'},\n","    {   'answer': 'sales would increase temperature rose',\n","        'context': ' study parameters mean parameter slope indicating amount '\n","                   'sales would increase temperature rose degree number seems '\n","                   '1674 units usddegree already seems '},\n","    {   'answer': 'innovative technology exploring engineering',\n","        'context': ' taking entire feature variable international journal '\n","                   'innovative technology exploring engineering ijitee issn '\n","                   '22783075 volume8 issue12 october 2019 47'},\n","    {   'answer': 'data analysis',\n","        'context': 'life informing boss supervisor you’ve 2 let’s consider '\n","                   'basic outline data analysis report detail 1 introduction '\n","                   'good features introduction include • s'}]\n"]}]}]}